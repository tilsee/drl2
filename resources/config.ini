[Common]
experiment_name : TestRun
configuration_save_path : C:\DRL\P2\drl2\experiments\${Common:experiment_name}\logs\configs\

[Kicker]
horizon : 1000
# Action space
continuous_act_space : True
multi_discrete_act_space : False
# Observation space
image_obs_space : False
# Episode definition
end_episode_on_struck_goal : True
end_episode_on_conceded_goal : True
reset_goalie_position : True
# Rendering
render_training : False
# Discrete parameters
lateral_bins : 5
angular_bins : 5
# Step frequency
step_frequency : 16

[Algorithm]
policy : MlpPolicy
# See SB3 documentation for available options and train.py for additional implementation requirements
;policy_kwargs : {'net_arch':{'pi':[64, 64], 'vf':[64, 64]}}
tensorboard_log : C:\DRL\P2\drl2\experiments\${Common:experiment_name}\logs\configs\

[Training]
total_timesteps : 2000000
tb_log_name : training_run

##########################################################################
################               DEFAULT ARGS               ################
##########################################################################

[Callback]
save_freq : 500000
save_path : C:\DRL\P2\drl2\experiments\${Common:experiment_name}\logs\configs\
save_replay_buffer : True
save_vecnormalize : True

[VideoRecording]
video_folder : C:\DRL\P2\drl2\experiments\${Common:experiment_name}\logs\configs\
video_interval : 100000
video_length : 750
